# Qsym : A Practical Concolic Execution Engine Tailored for Hybrid Fuzzing

This paper introduces a hybrid fuzzer named QSYM. The key idea is to integrate the symbolic emulation with the native execution, trying to take advantage of both side. Obviously, this is mentioned as concolic execution when we're talking about *symbolic execution*, but when we're talking about fuzzing, this becomes some kind of innovation (maybe it really does).

Here are their main contributions:

    1. Fast concolic execution through efficient emulation.

    2. Efficient repetitive testing and concrete environment.

    3. New heuristics for hybrid fuzzing 

    4. Some real-world bugs.



##### Some ideas

They abandon the IR (Intermediate Representation), which is universally used in symbolic execution platform such as angr, S2E, etc. Because:

    1. IR incurs additional overhead.

    2. IR blocks further optimization.



They also abandon the snapshot strategy, which is used in fuzzing. Because:

    1. fuzzing input does not share a common branch.

    2. snapshot cannot reflect external status.

    

They even don't gurantee their analysis sound (可靠的, 但是感觉reliable更舒服一点). Because:

    1. never-ending analysis for complex logic. (This is true, but in symbolic execution for exploit generation, we have to).

    2. sound analysis could over-constraint a path. (This is also true, but.. emm..  u know, we have to consider the difference between *vulnerability detection* and *exploit generation*)



##### Some practice of innovation

They adopt instruction-level symbolic execution. Apparently, this is in view of basic-block-level symbolic execution. **But are we really not using instruction-level symbolic execution in practice?**



They solve only relevant constraints. This is in view of the fact that some constraints really don't matter, such as user's name. But we have to consider the following questions:

    1. What is the judgement standard of relevant constraints.

    2. How do we automatically identify relevant constraints and discard irrelevant constraints?

Obviously, this paper didn't answer them.



They use symbolic execution to approach higher code coverage, so they don't care about how to solve the constraints. They just make use of constraints to get over simple obstacles to go deeper in the program's logic. This is the main difference between fuzzing and exploit generation.



They prune the basic blocks which are executed once and once and once again. The main reason of it is that they believe constraints repetitively generated by the same code are not useful for finding new code coverage in real-world software. **(Maybe? I don't know.....)**



## Conclusion

This paper mainly focuses on fuzzing, there may be some inspiration, but wouldn't help much now.






